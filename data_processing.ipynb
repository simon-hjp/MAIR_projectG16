{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from typing import Union\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"Data/Chat system questionnaire(1-21).xlsx\", sheet_name=\"Sheet1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESSING STEPS\n",
    "\n",
    "- Seperate each of the trials from one ID (but do assign the same ID) (unsure how to do this)\n",
    "  - Columns follow a semi-regularisable pattern; (no prefix, 2, 3, 4)\n",
    "- Encode ordinal category\n",
    "  - (strongly disagree, moderately disagree, do not agree nor disagree, moderately agree, strongly agree) -> (1,2,3,4,5)\n",
    "- Normal/inverse categories must be averaged (# I obtained [...] - # I did not obtain [...])\n",
    "- Calculate average for each subsequent aspect in each of the papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trial1 = df[['ID', 'Column', 'Start time','Completion time', 'Which version of the system did you use?\\n',\n",
    "       'I obtained all necessary information from the system.',\n",
    "       'I did not obtain all necessary information from the system.',\n",
    "       'I received correct information from the system.',\n",
    "       'I received incorrect information from the system.',\n",
    "       'The information given to me by the system was displayed properly.',\n",
    "       'The information given to me by the system was not displayed properly.',\n",
    "       'The system is dependable.', 'The system is independable.',\n",
    "       'The system is flexible with my inputs.',\n",
    "       'The system is rigid with my inputs.',\n",
    "       'The system is easily accessible.',\n",
    "       'The system is not easily accessible.',\n",
    "       'The system offered timely responses.',\n",
    "       'The responses were offered too slow by the system.',\n",
    "       'I perceived the system as natural.',\n",
    "       'I perceived the system as humanlike.',\n",
    "       'I perceived the system as conscious.',\n",
    "       'I perceived the system as lifelike', 'I perceived the system as fake.',\n",
    "       'I perceived the system as machinelike.',\n",
    "       'I perceived the system as unconscious.',\n",
    "       'I perceived the system as artificial.']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trial2 = df[['ID', 'Column', 'Start time','Completion time', 'Which version of the system did you use?\\n2',\n",
    "       'I obtained all necessary information from the system.2',\n",
    "       'I did not obtain all necessary information from the system.2',\n",
    "       'I received correct information from the system.2',\n",
    "       'I received incorrect information from the system.2',\n",
    "       'The information given to me by the system was displayed properly.2',\n",
    "       'The information given to me by the system was not displayed properly.2',\n",
    "       'The system is dependable.2', 'The system is independable.2',\n",
    "       'The system is flexible with my inputs.2',\n",
    "       'The system is rigid with my inputs.2',\n",
    "       'The system is easily accessible.2',\n",
    "       'The system is not easily accessible.2',\n",
    "       'The system offered timely responses.2',\n",
    "       'The responses were offered too slow by the system.2',\n",
    "       'I perceived the system as natural.2',\n",
    "       'I perceived the system as humanlike.2',\n",
    "       'I perceived the system as conscious.2',\n",
    "       'I perceived the system as lifelike2',\n",
    "       'I perceived the system as fake.2',\n",
    "       'I perceived the system as machinelike.2',\n",
    "       'I perceived the system as unconscious.2',\n",
    "       'I perceived the system as artificial.2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trial3 = df[['ID', 'Column', 'Start time','Completion time', 'Which version of the system did you use?\\n3',\n",
    "       'I obtained all necessary information from the system.3',\n",
    "       'I did not obtain all necessary information from the system.3',\n",
    "       'I received correct information from the system.3',\n",
    "       'I received incorrect information from the system.3',\n",
    "       'The information given to me by the system was displayed properly.3',\n",
    "       'The information given to me by the system was not displayed properly.3',\n",
    "       'The system is dependable.3', 'The system is independable.3',\n",
    "       'The system is flexible with my inputs.3',\n",
    "       'The system is rigid with my inputs.3',\n",
    "       'The system is easily accessible.3',\n",
    "       'The system is not easily accessible.3',\n",
    "       'The system offered timely responses.3',\n",
    "       'The responses were offered too slow by the system.3',\n",
    "       'I perceived the system as natural.3',\n",
    "       'I perceived the system as humanlike.3',\n",
    "       'I perceived the system as conscious.3',\n",
    "       'I perceived the system as lifelike3',\n",
    "       'I perceived the system as fake.3',\n",
    "       'I perceived the system as machinelike.3',\n",
    "       'I perceived the system as unconscious.3',\n",
    "       'I perceived the system as artificial.3',]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trial4 = df[['ID', 'Column', 'Start time','Completion time', 'Which version of the system did you use?\\n4',\n",
    "       'I obtained all necessary information from the system.4',\n",
    "       'I did not obtain all necessary information from the system.4',\n",
    "       'I received correct information from the system.4',\n",
    "       'I received incorrect information from the system.4',\n",
    "       'The information given to me by the system was displayed properly.4',\n",
    "       'The information given to me by the system was not displayed properly.4',\n",
    "       'The system is dependable.4', 'The system is independable.4',\n",
    "       'The system is flexible with my inputs.4',\n",
    "       'The system is rigid with my inputs.4',\n",
    "       'The system is easily accessible.4',\n",
    "       'The system is not easily accessible.4',\n",
    "       'The system offered timely responses.4',\n",
    "       'The responses were offered too slow by the system.4',\n",
    "       'I perceived the system as natural.4',\n",
    "       'I perceived the system as humanlike.4',\n",
    "       'I perceived the system as conscious.4',\n",
    "       'I perceived the system as lifelike4',\n",
    "       'I perceived the system as fake.4',\n",
    "       'I perceived the system as machinelike.4',\n",
    "       'I perceived the system as unconscious.4',\n",
    "       'I perceived the system as artificial.4']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_trial1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likert_decoder(likert: str) -> Union[int, str]:\n",
    "    dct = dict({\"Strongly disagree\": 1, \"Moderately disagree\": 2, \"Do not agree nor disagree\": 3, \"Moderately agree\": 4, \"Strongly agree\": 5})\n",
    "    if likert in dct.keys():\n",
    "        return dct[likert]\n",
    "    else:\n",
    "        return likert  # do not mutate unrelated strings\n",
    "    \n",
    "def likert_wrapper(series: pd.Series) -> pd.Series:\n",
    "    series_copy = series.copy()\n",
    "    series_copy = series_copy.apply(likert_decoder)\n",
    "    return series_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trial1 = df_trial1.apply(likert_wrapper, axis=0)\n",
    "df_trial2 = df_trial2.apply(likert_wrapper, axis=0)\n",
    "df_trial3 = df_trial3.apply(likert_wrapper, axis=0)\n",
    "df_trial4 = df_trial4.apply(likert_wrapper, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict(zip(df_trial2.columns, df_trial1.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trial2 = df_trial2.rename(columns=dict(zip(df_trial2.columns, df_trial1.columns)))\n",
    "df_trial3 = df_trial3.rename(columns=dict(zip(df_trial3.columns, df_trial1.columns)))\n",
    "df_trial4 = df_trial4.rename(columns=dict(zip(df_trial4.columns, df_trial1.columns)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trials = pd.concat([df_trial1, df_trial2, df_trial3, df_trial4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trials = df_trials.sort_index()\n",
    "df_trials = df_trials.sort_values([\"ID\", \"Which version of the system did you use?\\n\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_trials.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def variable_calc(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_copy = df.copy()\n",
    "    # columns containing necessary info\n",
    "    Q_complete = 'I obtained all necessary information from the system.'\n",
    "    QI_complete = 'I did not obtain all necessary information from the system.'  # Inverse\n",
    "    Q_accuracy = 'I received correct information from the system.'\n",
    "    QI_accuracy = 'I received incorrect information from the system.'\n",
    "    Q_format = 'The information given to me by the system was displayed properly.'\n",
    "    QI_format = 'The information given to me by the system was not displayed properly.'\n",
    "    Q_reliability = 'The system is dependable.'\n",
    "    QI_reliability = 'The system is independable.'\n",
    "    Q_flexibility = 'The system is flexible with my inputs.'\n",
    "    QI_flexibility = 'The system is rigid with my inputs.'\n",
    "    Q_accessibility = 'The system is easily accessible.'\n",
    "    QI_accessibility = 'The system is not easily accessible.'\n",
    "    Q_timeliness = 'The system offered timely responses.'\n",
    "    QI_timeliness = 'The responses were offered too slow by the system.'\n",
    "    Q_natural = 'I perceived the system as natural.'\n",
    "    QI_natural = 'I perceived the system as fake.'\n",
    "    Q_humanlike = 'I perceived the system as humanlike.'\n",
    "    QI_humanlike = 'I perceived the system as machinelike.'\n",
    "    Q_conscious = 'I perceived the system as conscious.'\n",
    "    QI_conscious = 'I perceived the system as unconscious.'\n",
    "    Q_lifelike = 'I perceived the system as lifelike'\n",
    "    QI_lifelike = 'I perceived the system as artificial.'\n",
    "    # Initial var extraction (normal+inverse)\n",
    "    df_copy[\"Completeness\"] = (df_trials[Q_complete] + (6 - df_trials[QI_complete])) / 2\n",
    "    df_copy[\"Accuracy\"] = (df_trials[Q_accuracy] + (6 - df_trials[QI_accuracy])) / 2\n",
    "    df_copy[\"Format\"] = (df_trials[Q_format] + (6 - df_trials[QI_format])) / 2\n",
    "    df_copy[\"Reliability\"] = (df_trials[Q_reliability] + (6 - df_trials[QI_reliability])) / 2\n",
    "    df_copy[\"Flexibility\"] = (df_trials[Q_flexibility] + (6 - df_trials[QI_flexibility])) / 2\n",
    "    df_copy[\"Accessibility\"] = (df_trials[Q_accessibility] + (6 - df_trials[QI_accessibility])) / 2\n",
    "    df_copy[\"Timeliness\"] = (df_trials[Q_timeliness] + (6 - df_trials[QI_timeliness])) / 2\n",
    "    df_copy[\"Natural\"] = (df_trials[Q_natural] + (6 - df_trials[QI_natural])) / 2\n",
    "    df_copy[\"Humanlike\"] = (df_trials[Q_humanlike] + (6 - df_trials[QI_humanlike])) / 2\n",
    "    df_copy[\"Conscious\"] = (df_trials[Q_conscious] + (6 - df_trials[QI_conscious])) / 2\n",
    "    df_copy[\"Lifelike\"] = (df_trials[Q_lifelike] + (6 - df_trials[QI_lifelike])) / 2\n",
    "    # Dependent variable calculation\n",
    "    # User satisfaction (aka usefulness/ease of use)\n",
    "    df_copy[\"Information Quality\"] = (df_copy[\"Completeness\"] + df_copy[\"Accuracy\"] + df_copy[\"Format\"]) / 3\n",
    "    df_copy[\"System Quality\"] = (df_copy[\"Reliability\"] + df_copy[\"Flexibility\"] + df_copy[\"Accessibility\"] + df_copy[\"Timeliness\"]) / 4\n",
    "    df_copy[\"Information satisfaction\"] = (df_copy[\"System Quality\"] + df_copy[\"Information Quality\"]) / 2\n",
    "    df_copy[\"Usefulness\"] = (df_copy[\"Information satisfaction\"] + df_copy[\"System Quality\"]) / 2\n",
    "    df_copy[\"Ease of use\"] = df_copy[\"System Quality\"]  # Never changes according to the paper\n",
    "    # Anthropomorphism\n",
    "    df_copy[\"Anthropomorphism\"] = (df_copy[\"Natural\"] + df_copy[\"Humanlike\"] + df_copy[\"Conscious\"] + df_copy[\"Lifelike\"]) / 4\n",
    "    # Done\n",
    "    return df_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trials_vars = variable_calc(df_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_trials_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some sample data\n",
    "V1 = df_trials_vars[ df_trials_vars['Which version of the system did you use?\\n']=='Version 1']\n",
    "V2 = df_trials_vars[ df_trials_vars['Which version of the system did you use?\\n']=='Version 2']\n",
    "V3 = df_trials_vars[ df_trials_vars['Which version of the system did you use?\\n']=='Version 3']\n",
    "V4 = df_trials_vars[ df_trials_vars['Which version of the system did you use?\\n']=='Version 4']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1_ease = np.mean(V1['Ease of use'])\n",
    "v1_useful = np.mean(V1['Usefulness'])\n",
    "v1_anthro = np.mean(V1['Anthropomorphism'])\n",
    "\n",
    "v2_ease = np.mean(V2['Ease of use'])\n",
    "v2_useful = np.mean(V2['Usefulness'])\n",
    "v2_anthro = np.mean(V2['Anthropomorphism'])\n",
    "\n",
    "v3_ease = np.mean(V3['Ease of use'])\n",
    "v3_useful = np.mean(V3['Usefulness'])\n",
    "v3_anthro = np.mean(V3['Anthropomorphism'])\n",
    "\n",
    "v4_ease = np.mean(V4['Ease of use'])\n",
    "v4_useful = np.mean(V4['Usefulness'])\n",
    "v4_anthro = np.mean(V4['Anthropomorphism'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# testing for ingo, no need to run this cell\n",
    "\n",
    "print(int(df_trials_vars.shape[0]/4))\n",
    "\n",
    "print(*range(int(df_trials_vars.shape[0]/4)))\n",
    "\n",
    "person = df_trials_vars[ df_trials_vars['ID']==5]\n",
    "\n",
    "print(person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ease_data = np.array([v1_ease, v2_ease, v3_ease, v4_ease])\n",
    "usefulness_data = np.array([v1_useful, v2_useful, v3_useful, v4_useful])\n",
    "anthro_data = np.array([v1_anthro, v2_anthro, v3_anthro, v4_anthro])\n",
    "\n",
    "categories = ['Version 1', 'Version 2', 'Version 3', 'Version 4']\n",
    "\n",
    "# Create a figure with three subplots arranged vertically\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(8, 8))\n",
    "\n",
    "# Plot the data on each subplot\n",
    "ax1.bar(categories, ease_data, color='blue', alpha=0.7, label='Data 1')\n",
    "ax2.bar(categories, usefulness_data, color='green', alpha=0.7, label='Data 2')\n",
    "ax3.bar(categories, anthro_data, color='red', alpha=0.7, label='Data 3')\n",
    "\n",
    "# Customize each subplot\n",
    "ax1.set_title('Ease of use')\n",
    "ax2.set_title('Usefulness')\n",
    "ax3.set_title('Anthropomorphism')\n",
    "\n",
    "# Add some spacing between subplots\n",
    "plt.subplots_adjust(hspace=0.6)\n",
    "\n",
    "num_of_trials = df_trials_vars.shape[0]\n",
    "num_of_participants = int(np.floor(num_of_trials / 4))\n",
    "\n",
    "\n",
    "import matplotlib.colors as mcolors\n",
    "named_colors = list(mcolors.CSS4_COLORS.values())\n",
    "random.shuffle(named_colors)\n",
    "    \n",
    "linewidth = 1    \n",
    "dot_size = 6\n",
    "\n",
    "# ease of use\n",
    "for people in range(num_of_participants):\n",
    "    color = named_colors[people]\n",
    "    people += 1 # because the excel ID begins at 1\n",
    "    \n",
    "    person = df_trials_vars[ df_trials_vars['ID']==people]\n",
    "    x_pos = [0,1,2,3]\n",
    "    \n",
    "    ax1.plot(x_pos,person['Ease of use'],color=color, linewidth=linewidth)\n",
    "    ax1.scatter(x_pos,person['Ease of use'],color=color,s=dot_size)\n",
    "\n",
    "    # Usefulness\n",
    "    ax2.plot(x_pos,person['Usefulness'],color=color, linewidth=linewidth)\n",
    "    ax2.scatter(x_pos,person['Usefulness'],color=color,s=dot_size)\n",
    "\n",
    "\n",
    "    # Anthropomorphism\n",
    "    ax3.plot(x_pos,person['Anthropomorphism'],color=color, linewidth=linewidth)\n",
    "    ax3.scatter(x_pos,person['Anthropomorphism'],color=color,s=dot_size)\n",
    "\n",
    "# Display the plot\n",
    "\n",
    "# Add legends\n",
    "#ax1.legend()\n",
    "#ax2.legend()\n",
    "#ax3.legend()\n",
    "\n",
    "ax1.set_ylabel(\"Score ( Likert 1-5)\")\n",
    "ax2.set_ylabel(\"Score ( Likert 1-5)\")\n",
    "ax3.set_ylabel(\"Score ( Likert 1-5)\")\n",
    "\n",
    "ax1.set_yticks(np.arange(1, 6, 1))\n",
    "ax2.set_yticks(np.arange(1, 6, 1))\n",
    "ax3.set_yticks(np.arange(1, 6, 1))\n",
    "plt.savefig(\"custom_plot.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
